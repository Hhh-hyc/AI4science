<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" >
  <!-- The Head -->

<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  >

  

  

  
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.2" />
<meta property="og:title" content="PINNs_Inference" />
<meta property="og:locale" content="en" />
<meta name="description" content="Trained to solve supervised learning tasks, Physic-informed neural networks (PINNs) are defined for two classes of problems: data-driven solution and data-driven discovery of partial differential equations (PDEs)." />
<meta property="og:description" content="Trained to solve supervised learning tasks, Physic-informed neural networks (PINNs) are defined for two classes of problems: data-driven solution and data-driven discovery of partial differential equations (PDEs)." />
<link rel="canonical" href="https://hhh-hyc.github.io/AI4science/posts/pinns/" />
<meta property="og:url" content="https://hhh-hyc.github.io/AI4science/posts/pinns/" />
<meta property="og:site_name" content="AI for science" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-11-04T12:00:00+08:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="PINNs_Inference" />
<meta name="twitter:site" content="@twitter_username" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-11-30T22:18:08+08:00","datePublished":"2023-11-04T12:00:00+08:00","description":"Trained to solve supervised learning tasks, Physic-informed neural networks (PINNs) are defined for two classes of problems: data-driven solution and data-driven discovery of partial differential equations (PDEs).","headline":"PINNs_Inference","mainEntityOfPage":{"@type":"WebPage","@id":"https://hhh-hyc.github.io/AI4science/posts/pinns/"},"url":"https://hhh-hyc.github.io/AI4science/posts/pinns/"}</script>
<!-- End Jekyll SEO tag -->

  

  <title>PINNs_Inference | AI for science
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/AI4science/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/AI4science/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/AI4science/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/AI4science/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/AI4science/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="AI for science">
<meta name="application-name" content="AI for science">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/AI4science/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.2/css/all.min.css">

  <link rel="stylesheet" href="/AI4science/assets/css/jekyll-theme-chirpy.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.21.2/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  
    <!-- Switch the mode between dark and light. -->

<script type="text/javascript">
  class ModeToggle {
    static get MODE_KEY() {
      return 'mode';
    }
    static get MODE_ATTR() {
      return 'data-mode';
    }
    static get DARK_MODE() {
      return 'dark';
    }
    static get LIGHT_MODE() {
      return 'light';
    }
    static get ID() {
      return 'mode-toggle';
    }

    constructor() {
      if (this.hasMode) {
        if (this.isDarkMode) {
          if (!this.isSysDarkPrefer) {
            this.setDark();
          }
        } else {
          if (this.isSysDarkPrefer) {
            this.setLight();
          }
        }
      }

      let self = this;

      /* always follow the system prefers */
      this.sysDarkPrefers.addEventListener('change', () => {
        if (self.hasMode) {
          if (self.isDarkMode) {
            if (!self.isSysDarkPrefer) {
              self.setDark();
            }
          } else {
            if (self.isSysDarkPrefer) {
              self.setLight();
            }
          }

          self.clearMode();
        }

        self.notify();
      });
    } /* constructor() */

    get sysDarkPrefers() {
      return window.matchMedia('(prefers-color-scheme: dark)');
    }

    get isSysDarkPrefer() {
      return this.sysDarkPrefers.matches;
    }

    get isDarkMode() {
      return this.mode === ModeToggle.DARK_MODE;
    }

    get isLightMode() {
      return this.mode === ModeToggle.LIGHT_MODE;
    }

    get hasMode() {
      return this.mode != null;
    }

    get mode() {
      return sessionStorage.getItem(ModeToggle.MODE_KEY);
    }

    /* get the current mode on screen */
    get modeStatus() {
      if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer)) {
        return ModeToggle.DARK_MODE;
      } else {
        return ModeToggle.LIGHT_MODE;
      }
    }

    setDark() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.DARK_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE);
    }

    setLight() {
      document.documentElement.setAttribute(ModeToggle.MODE_ATTR, ModeToggle.LIGHT_MODE);
      sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE);
    }

    clearMode() {
      document.documentElement.removeAttribute(ModeToggle.MODE_ATTR);
      sessionStorage.removeItem(ModeToggle.MODE_KEY);
    }

    /* Notify another plugins that the theme mode has changed */
    notify() {
      window.postMessage(
        {
          direction: ModeToggle.ID,
          message: this.modeStatus
        },
        '*'
      );
    }

    flipMode() {
      if (this.hasMode) {
        if (this.isSysDarkPrefer) {
          if (this.isLightMode) {
            this.clearMode();
          } else {
            this.setLight();
          }
        } else {
          if (this.isDarkMode) {
            this.clearMode();
          } else {
            this.setDark();
          }
        }
      } else {
        if (this.isSysDarkPrefer) {
          this.setLight();
        } else {
          this.setDark();
        }
      }

      this.notify();
    } /* flipMode() */
  } /* ModeToggle */

  const modeToggle = new ModeToggle();
</script>

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/AI4science/" id="avatar" class="rounded-circle">
      
        
        <img src="/AI4science/Duck.jpeg" width="112" height="112" alt="avatar" onerror="this.style.display='none'">
      
    </a>

    <h1 class="site-title">
      <a href="/AI4science/">AI for science</a>
    </h1>
    <p class="site-subtitle fst-italic mb-0">Interpretability, explaination, causality</p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/AI4science/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/AI4science/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/AI4science/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/AI4science/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/AI4science/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    
      <button type="button" class="mode-toggle btn" aria-label="Switch Mode">
        <i class="fas fa-adjust"></i>
      </button>

      
        <span class="icon-border"></span>
      
    

    
      

      
        <a
          href="https://github.com/Hhh-hyc"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['ychu2020_st','rcees.ac.cn'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href=""
          aria-label="linkedin"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-linkedin"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/AI4science/">
                Home
              </a>
            </span>

          
        
          
        
          
            
              <span>PINNs_Inference</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->





<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  




<!-- return -->




<article class="px-1">
  <header>
    <h1 data-toc-skip>PINNs_Inference</h1>

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1699070400"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Nov  4, 2023
</time>

      </span>

      <!-- lastmod date -->
      
        <span>
          Updated
          <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1701353888"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Nov 30, 2023
</time>

        </span>
      

      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://github.com/Hhh-hyc/AI4science">YC</a>
            
          </em>
        </span>

        <!-- read time -->
        <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="1333 words"
>
  <em>7 min</em> read</span>

      </div>
      <!-- .d-flex -->
    </div>
    <!-- .post-meta -->
  </header>

  <div class="content">
    <p>Trained to solve <code class="language-plaintext highlighter-rouge">supervised learning</code> tasks, Physic-informed neural networks (PINNs) are defined for two classes of problems:
data-driven solution and data-driven discovery of partial differential equations (PDEs).</p>

<h3 id="data-driven-solution"><span class="me-2">Data-driven solution</span><a href="#data-driven-solution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p>Given a general form of PDEs $f(t,x)$, PINN could get to the solution $u(t,x)$ of this 1-dimensional non-linear equation with only small amount of training data, namely initial and boundary conditions of $u(t,x)$ as well as the sampled data of $f(t,x)$.</p>

<h4 id="continuous-time-inference-equation-burgers-equation"><span class="me-2">Continuous time inference equation: Burger’s equation</span><a href="#continuous-time-inference-equation-burgers-equation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>

\[f(t,x)=u_{t}+uu_{xx}-(0.01/\pi)u_{xx}\]

<p>By minimizing the mean square error loss $MSE_{u}+MSE_{f}$, including the data measurements of $u(t,x)$ at initial and boundary conditions, and the supervised loss of the Burger’s equation, $u(t,x)$ is accurately simulated by neural networks.</p>

\[MSE_{u}=\frac{1}{N_{u}}\sum_{i=0}^{N_{u}}\lvert u(t_{u}^{i},x_{u}^{i})-u^{i} \rvert^2\]

\[MSE_{f}=\frac{1}{N_{f}}\sum_{i=0}^{N_{f}}\lvert f(t_{f}^{i},x_{f}^{i}) \rvert^2\]

<p>Steps are as follows.</p>

<ol>
  <li>Weights between layers are defined like <code class="language-plaintext highlighter-rouge">xavier_init</code>
    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">xavier_init</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">size</span><span class="p">):</span>
     <span class="n">in_dim</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
     <span class="n">out_dim</span> <span class="o">=</span> <span class="n">size</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>        
     <span class="n">xavier_stddev</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="n">in_dim</span> <span class="o">+</span> <span class="n">out_dim</span><span class="p">))</span>
     <span class="k">return</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">truncated_normal</span><span class="p">([</span><span class="n">in_dim</span><span class="p">,</span> <span class="n">out_dim</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="n">xavier_stddev</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div>    </div>
  </li>
  <li>Given the number of <code class="language-plaintext highlighter-rouge">layers</code>, weights and biases are produced by <code class="language-plaintext highlighter-rouge">initialize_NN</code>
    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">initialize_NN</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">layers</span><span class="p">):</span>        
     <span class="n">weights</span> <span class="o">=</span> <span class="p">[]</span>
     <span class="n">biases</span> <span class="o">=</span> <span class="p">[]</span>
     <span class="n">num_layers</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">layers</span><span class="p">)</span> 
     <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">num_layers</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
         <span class="n">W</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">xavier_init</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">[</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="p">],</span> <span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]])</span>
         <span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nc">Variable</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">zeros</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span><span class="n">layers</span><span class="p">[</span><span class="n">l</span><span class="o">+</span><span class="mi">1</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)</span>
         <span class="n">weights</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>
         <span class="n">biases</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>        
     <span class="k">return</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span>
</pre></td></tr></tbody></table></code></div>    </div>
  </li>
  <li>Given weights and biases, a complete neural network without the final activation is designed by <code class="language-plaintext highlighter-rouge">neural_net</code>
    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">neural_net</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">weights</span><span class="p">,</span> <span class="n">biases</span><span class="p">):</span>
     <span class="n">num_layers</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span>
     <span class="n">H</span> <span class="o">=</span> <span class="mf">2.0</span><span class="o">*</span><span class="p">(</span><span class="n">X</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">lb</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">ub</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">lb</span><span class="p">)</span> <span class="o">-</span> <span class="mf">1.0</span>
     <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="n">num_layers</span><span class="o">-</span><span class="mi">2</span><span class="p">):</span>
         <span class="n">W</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
         <span class="n">b</span> <span class="o">=</span> <span class="n">biases</span><span class="p">[</span><span class="n">l</span><span class="p">]</span>
         <span class="n">H</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">b</span><span class="p">))</span>
     <span class="n">W</span> <span class="o">=</span> <span class="n">weights</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
     <span class="n">b</span> <span class="o">=</span> <span class="n">biases</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
     <span class="n">Y</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">tanh</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">add</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">H</span><span class="p">,</span> <span class="n">W</span><span class="p">),</span> <span class="n">b</span><span class="p">))</span> <span class="c1"># YC: tf.tanh was personally added.
</span>     <span class="k">return</span> <span class="n">Y</span>
</pre></td></tr></tbody></table></code></div>    </div>
    <p>where, <code class="language-plaintext highlighter-rouge">H</code> seems like restricting the value of the first layer within [-1,1].</p>
  </li>
  <li>As weights, <code class="language-plaintext highlighter-rouge">dummy_x0(x1)_tf</code> is identical matirx of <code class="language-plaintext highlighter-rouge">x0(x1)</code> rows, and are thus replaced by <code class="language-plaintext highlighter-rouge">x0(x1)</code>. Besides, to adjust to the tf 2.x framework, tf. gradients() was replaced with tf.GradientTape(), and gradient process was merged into the core part of representing loss functions in PINNs.
    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">net_U0</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="c1"># YC: using GradientTape instead of gradients
</span>     <span class="k">with</span> <span class="n">tf</span><span class="p">.</span><span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">g</span><span class="p">:</span>
             <span class="n">g</span><span class="p">.</span><span class="nf">watch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
             <span class="k">with</span> <span class="n">tf</span><span class="p">.</span> <span class="nc">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">gg</span><span class="p">:</span>
                     <span class="n">gg</span><span class="p">.</span><span class="nf">watch</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
                     <span class="n">U1</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">neural_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">biases</span><span class="p">)</span>
                     <span class="n">U</span> <span class="o">=</span> <span class="n">U1</span><span class="p">[:,:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
             <span class="n">U_x</span> <span class="o">=</span> <span class="n">gg</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">U</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
     <span class="n">U_xx</span> <span class="o">=</span> <span class="n">gg</span><span class="p">.</span><span class="nf">gradient</span><span class="p">(</span><span class="n">U_x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
     <span class="n">F</span> <span class="o">=</span> <span class="mf">5.0</span><span class="o">*</span><span class="n">U</span> <span class="o">-</span> <span class="mf">5.0</span><span class="o">*</span><span class="n">U</span><span class="o">**</span><span class="mi">3</span> <span class="o">+</span> <span class="mf">0.0001</span><span class="o">*</span><span class="n">U_xx</span>
     <span class="n">Ut</span> <span class="o">=</span> <span class="n">U1</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">dt</span><span class="o">*</span><span class="n">tf</span><span class="p">.</span><span class="nf">matmul</span><span class="p">(</span><span class="n">F</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">IRK_weights</span><span class="p">.</span><span class="n">T</span><span class="p">)</span> <span class="c1"># dt was only used here in the PINNs to represent the linear variation in the dimension of t. U1 denotes the solution at t0, and Ut denotes the solution at t1, where t1-t0=dt.
</span>     <span class="k">return</span> <span class="n">Ut</span> 
<span class="k">def</span> <span class="nf">net_U1</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="c1"># x1
</span>     <span class="n">U1</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">neural_net</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">weights</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">biases</span><span class="p">)</span>
     <span class="n">U1_x</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">fwd_gradients_1</span><span class="p">(</span><span class="n">U1</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
     <span class="k">return</span> <span class="n">U1</span><span class="p">,</span> <span class="n">U1_x</span>   
</pre></td></tr></tbody></table></code></div>    </div>
  </li>
  <li><code class="language-plaintext highlighter-rouge">loss</code> is defined by loss between the prediction (U0_pred) and the measurement(u0) of the PDE solution ($u(t,x)$) as well as the loss of boundary condition, represented by U1.
    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre></td><td class="rouge-code"><pre><span class="n">self</span><span class="p">.</span><span class="n">U0_pred</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">net_U0</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">x0_tf</span><span class="p">)</span> 
<span class="n">self</span><span class="p">.</span><span class="n">U1_pred</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">U1_x_pred</span><span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">net_U1</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">x1_tf</span><span class="p">)</span> 
<span class="n">self</span><span class="p">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">u0_tf</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">U0_pred</span><span class="p">))</span> <span class="o">+</span> \  
            <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">U1_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">U1_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]))</span> <span class="o">+</span> \
            <span class="n">tf</span><span class="p">.</span><span class="nf">reduce_sum</span><span class="p">(</span><span class="n">tf</span><span class="p">.</span><span class="nf">square</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">U1_x_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,:]</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">U1_x_pred</span><span class="p">[</span><span class="mi">1</span><span class="p">,:]))</span> 
</pre></td></tr></tbody></table></code></div>    </div>
  </li>
  <li>To minimize the loss function, optimizers, <code class="language-plaintext highlighter-rouge">Adam</code> and <code class="language-plaintext highlighter-rouge">L-BFGS</code>, were utilized in sequence. The appliance of L-BFGS was updated in tf 2.x framework and updated as follows.
    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
</pre></td><td class="rouge-code"><pre><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">nIter</span><span class="p">):</span>
     <span class="n">tf_dict</span> <span class="o">=</span> <span class="p">{</span><span class="n">self</span><span class="p">.</span><span class="n">x0_tf</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">x0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">u0_tf</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">u0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">x1_tf</span><span class="p">:</span> <span class="n">self</span><span class="p">.</span><span class="n">x1</span><span class="p">}</span>
     <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
     <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">nIter</span><span class="p">):</span>
         <span class="n">self</span><span class="p">.</span><span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">train_op_Adam</span><span class="p">,</span> <span class="n">tf_dict</span><span class="p">)</span>
         <span class="c1"># Print
</span>         <span class="k">if</span> <span class="n">it</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
             <span class="n">elapsed</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span> <span class="o">-</span> <span class="n">start_time</span>
             <span class="n">loss_value</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">sess</span><span class="p">.</span><span class="nf">run</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">tf_dict</span><span class="p">)</span>
             <span class="nf">print</span><span class="p">(</span><span class="sh">'</span><span class="s">It: %d, Loss: %.3e, Time: %.2f</span><span class="sh">'</span> <span class="o">%</span> 
                   <span class="p">(</span><span class="n">it</span><span class="p">,</span> <span class="n">loss_value</span><span class="p">,</span> <span class="n">elapsed</span><span class="p">))</span>
             <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="p">.</span><span class="nf">time</span><span class="p">()</span>
     <span class="n">start</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">x0</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="sh">"</span><span class="s">float64</span><span class="sh">"</span><span class="p">)</span>
     <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tfp</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">lbfgs_minimize</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">loss</span><span class="p">,</span>
                                                   <span class="n">max_iterations</span> <span class="o">=</span> <span class="mi">50000</span><span class="p">,</span>
                                                   <span class="n">initial_position</span> <span class="o">=</span> <span class="n">start</span><span class="p">,</span>
                                                   <span class="n">num_correction_pairs</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>
                                                   <span class="n">max_line_search_iterations</span> <span class="o">=</span> <span class="mi">50</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div>    </div>
  </li>
  <li>input data:
    <ul>
      <li>$x0$ is a list of sampled input x.</li>
      <li>$u0$ is randomly selected through the PDE solution, $u(t,x)$, at specific position, $x0$ and $t0$.</li>
      <li>$x1$ is vertically stacked data [-1,1], the boundary condition.</li>
      <li>$dt$ is the random length of <code class="language-plaintext highlighter-rouge">t</code>, $t1-t0$, where $t0$ correponds to the position of $u0$.</li>
      <li><code class="language-plaintext highlighter-rouge">layers</code> is a list, representing the strusture of $f(t,x)$.</li>
    </ul>
  </li>
  <li>With tThe model.train()</li>
  <li>In the prediction of the PDE solution at the condition of $x^{<em>}$ and $t1$, the error between the predicted $u(t1,x^{</em>})$ and the measurement is defined as follows to show the accuracy. A smaller error shows a better accuracy.
    <div class="language-python highlighter-rouge"><div class="code-header">
        <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span>
      <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre></td><td class="rouge-code"><pre><span class="n">error</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">U1_pred</span><span class="p">[:,</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">-</span> <span class="n">Exact</span><span class="p">[</span><span class="n">idx_t1</span><span class="p">,:],</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">norm</span><span class="p">(</span><span class="n">Exact</span><span class="p">[</span><span class="n">idx_t1</span><span class="p">,:],</span> <span class="mi">2</span><span class="p">)</span>
</pre></td></tr></tbody></table></code></div>    </div>
  </li>
</ol>

<p><strong>Potential problems</strong></p>
<ul>
  <li>In training, model.predict() gets two objects from net_U1(), the simulated output of $u(t,x)$ and $\frac{\partial u}{\partial x}$, but the error calculated in <code class="language-plaintext highlighter-rouge">step 7</code> may not deal with the gradient?</li>
</ul>

<p><strong>Changes in versions of tensorflow</strong></p>
<ul>
  <li>tf.compat.v1 should be added in front of some old v1 functions in v2 version of tensorflow.</li>
  <li><code class="language-plaintext highlighter-rouge">L-BFGS-B</code> method in tf.opt.ScipyOptimizerInterface could be replaced by tensorflow_probability.optimizer.lbfgs_minimize()</li>
</ul>

<p><strong>Explanations in programming</strong></p>
<ul>
  <li><code class="language-plaintext highlighter-rouge">tf.placeholder()</code> generates a map, different from tf. Varaibles() and tf.Tensor(). This type is hashable, while the other two are not.
    <ul>
      <li>placeholder() with newly named input <code class="language-plaintext highlighter-rouge">x0_tf</code> as tf_dict.keys() for <code class="language-plaintext highlighter-rouge">feed_dict</code> is irreplaceable.</li>
    </ul>
  </li>
  <li><code class="language-plaintext highlighter-rouge">tf.compat.v1.disable_eager_execution()</code> couldn’t be used, as in resources_variable_ops.py script, self.numpy() wouldn’t be implemented.
    <ul>
      <li>If the <code class="language-plaintext highlighter-rouge">disable_eager_execution()</code> is used, then <code class="language-plaintext highlighter-rouge">tensor.ref()</code> is useless.</li>
      <li>To avoid Error: loss in Adam should be a function in eager execution,  as a result, 
    * <code class="language-plaintext highlighter-rouge">tf.compat.v1.placeholder()</code> couldn’t be replaced by <code class="language-plaintext highlighter-rouge">tensor.ref()</code>.
    * <code class="language-plaintext highlighter-rouge">tf.gradients()</code> is taken place by <code class="language-plaintext highlighter-rouge">tf.GradientTape()</code>, which requires targets to be a list or nested tensors. In the case of deep learning, the forward function should be appplied within GradientTape().</li>
    </ul>
  </li>
  <li>Why both Adam and L-BFGS optimizer were used.
    <ul>
      <li>With only Adam, the error calculated by <code class="language-plaintext highlighter-rouge">np.linalg.norm$ between</code> U1_pred[:,-1] (512,1) and $x$ (1, 512) is 1.37,</li>
      <li>With both Adam and L-BFGS, the error is smaller</li>
    </ul>
  </li>
  <li>The effect of appending <code class="language-plaintext highlighter-rouge">tanh</code> in neural_net function.</li>
  <li>Effects of removing dummy_x0(x1)
    <ul>
      <li>They are removed in tf.GradientTape()</li>
    </ul>
  </li>
</ul>

<h4 id="continuous-time-inference-equation-shrödinger-equation"><span class="me-2">Continuous time inference equation: Shrödinger equation</span><a href="#continuous-time-inference-equation-shrödinger-equation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>It’s noticed that Burger’s equation is one-dimemsional equation, and the temporal variation is linearly represented. So, the difference in applying PINNs in a more complex equation is shown. The loss function contains initial conditions($MSE_{0}$), boundary conditions($MSE_{b}$), and data of PDE($MSE_{f}$). And it is noticeable that $MSE_{b}$ considers both $h$ and $h_{x}$.</p>

\[\begin{align}
&amp;ih_{t}+0.5h_{xx}+\lvert h \rvert^{2} = 0, x \in [-5,5], t \in [0, \pi/2] \\
&amp;h(0,x)=2sech(x) \\
&amp;h(t,-5)=h(t,5) \\
&amp;h_{x}(t,-5)=h_{x}(t,5) \\
\end{align}\]

<h4 id="difference-between-discrete-time-inference-and-continuous-one"><span class="me-2">Difference between discrete time inference and continuous one</span><a href="#difference-between-discrete-time-inference-and-continuous-one" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h4>
<p>The biggest difference between discrete time inference and continuous one lies in the representation of the solution $u(x,t)$, where the last layer of the neural network is not 1 but q in usage, because it is exhibited by Runge-Kutta methods with q stages.</p>

<p><strong>Personal views</strong></p>
<ul>
  <li>The innovation lies in the treatment of loss function</li>
  <li>The difference between <code class="language-plaintext highlighter-rouge">PINNs</code> and <code class="language-plaintext highlighter-rouge">adding physics constraints into loss function</code><sup id="fnref:foot1" role="doc-noteref"><a href="#fn:foot1" class="footnote" rel="footnote">1</a></sup> ?
      + PINNs gives a solution of PDE, with physical elements included in the loss function. It’s a NN-based algorithm, different from the latter that is process-based model with auxiliary physical concepts in the loss function. From my perspective, since PINNs could be further developped in the exploration of causality in the process-based models, typically in the environemntal sciences, because PDE is also a part of the complex process-based model. Apart from the differece, PINN is more like the physics-constrained machine learning<sup id="fnref:foot2" role="doc-noteref"><a href="#fn:foot2" class="footnote" rel="footnote">2</a></sup>, which takes place of an emipirical parameter in a complex equation. Therefore, with the explicit desrciption provided by PINNs and the causality explored by environemntal experiments, it is prospective to decribe the whole complex model, with reasonably devised sub NNs to dive into the mechanisms in real life.</li>
</ul>

<p><strong>Further development</strong></p>
<ul>
  <li>As mentioned in <code class="language-plaintext highlighter-rouge">Personal Views</code>, PINNs is potential to be not only a solution but to be updated with more causality in its architecture and applied in describing a complex system with better interpretability.</li>
</ul>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:foot1" role="doc-endnote">
      <p>Chen H, Huang J J, Dash S S, et al. A hybrid deep learning framework with physical process description for simulation of evapotranspiration[J]. Journal of Hydrology, 2022, 606: 127422. <a href="#fnref:foot1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:foot2" role="doc-endnote">
      <p>Zhao, W. L., Gentine, P., Reichstein, M., Zhang, Y., Zhou, S., Wen, Y., et al. (2019). Physics-constrained machine learning of evapotranspiration. Geophysical Research Letters, 46, 14496–14507. https://doi.org/10.1029/2019GL085291. <a href="#fnref:foot2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/AI4science/categories/computational-sciences/">Computational sciences</a>,
          <a href="/AI4science/categories/scientific-machine-learning/">scientific machine learning</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/AI4science/tags/pinn/"
            class="post-tag no-text-decoration"
          >pinn</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted me-1">Share</span>
  <span class="share-icons">
    
    
    

    
      
      <a
        href="https://twitter.com/intent/tweet?text=PINNs_Inference%20-%20AI%20for%20science&url=https%3A%2F%2Fhhh-hyc.github.io%2FAI4science%2Fposts%2Fpinns%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Twitter"
        target="_blank"
        rel="noopener"
        aria-label="Twitter"
      >
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    
      
      <a
        href="https://www.facebook.com/sharer/sharer.php?title=PINNs_Inference%20-%20AI%20for%20science&u=https%3A%2F%2Fhhh-hyc.github.io%2FAI4science%2Fposts%2Fpinns%2F"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Facebook"
        target="_blank"
        rel="noopener"
        aria-label="Facebook"
      >
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    
      
      <a
        href="https://t.me/share/url?url=https%3A%2F%2Fhhh-hyc.github.io%2FAI4science%2Fposts%2Fpinns%2F&text=PINNs_Inference%20-%20AI%20for%20science"
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Telegram"
        target="_blank"
        rel="noopener"
        aria-label="Telegram"
      >
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted">
            <div class="access">
              <!-- Get the last 5 posts from lastmod list. -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/AI4science/posts/pinns/">PINNs_Inference</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/AI4science/posts/categories/">Preface</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/AI4science/posts/h2m/">Hybrid hydrologcial models</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/pinn/">pinn</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/hybrid-models/">hybrid models</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/causal-deep-learning/">causal deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/deeponet/">deeponet</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/scientific-machine-learning/">scientific machine learning</a>
      
    </div>
  </section>


            </div>

            
              
              



  <section id="toc-wrapper" class="ps-0 pe-4">
    <h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->














  

  

  

  

  

  

  

  

  

  

  

  

  

  
    
  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/AI4science/posts/pinn2-md/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1699588800"
  data-df="ll"
  
>
  Nov 10, 2023
</time>

              <h4 class="pt-0 my-2">PINNs_Discovery</h4>
              <div class="text-muted">
                <p>
                  





                  SIMILAR to the former blog, the accurately learnt neural networks could also be beneficial when architectures are already known.

Data-driven discovery for inverse problems
Upon solving inverse pro...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/AI4science/posts/categories/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1698508800"
  data-df="ll"
  
>
  Oct 29, 2023
</time>

              <h4 class="pt-0 my-2">Preface</h4>
              <div class="text-muted">
                <p>
                  





                  Great progresses have been made by researchers for the mutual devleopment between physically-based models (mechanism models) and Artificial intelligence (AI for short). Several typical milestones r...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/AI4science/posts/deeponet/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1700193600"
  data-df="ll"
  
>
  Nov 17, 2023
</time>

              <h4 class="pt-0 my-2">DeepONet</h4>
              <div class="text-muted">
                <p>
                  





                  “Inspired from the universal approximation theorem, neural networks with a single layer could not only approximates continuous functions, but also continuous functional or operators”1

Concepts

fu...
                </p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/AI4science/posts/h2m/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>Hybrid hydrologcial models</p>
    </a>
  

  
    <a
      href="/AI4science/posts/pinn2-md/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>PINNs_Discovery</p>
    </a>
  
</nav>

            
              
              <!--  The comments switcher -->


            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>
    ©
    <time>2023</time>
    <a href="https://github.com/Hhh-hyc/AI4science">YC</a>.
    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>Using the <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
  
    
    
    
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/pinn/">pinn</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/hybrid-models/">hybrid models</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/causal-deep-learning/">causal deep learning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/deeponet/">deeponet</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/AI4science/tags/scientific-machine-learning/">scientific machine learning</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- JavaScripts -->

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.10/dayjs.min.js,npm/dayjs@1.11.10/locale/en.min.js,npm/dayjs@1.11.10/plugin/relativeTime.min.js,npm/dayjs@1.11.10/plugin/localizedFormat.min.js,npm/tocbot@4.21.2/dist/tocbot.min.js,npm/mermaid@10.5.0/dist/mermaid.min.js"></script>






<script defer src="/AI4science/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    
      <!-- mermaid-js loader -->
<script type="text/javascript">
  (function () {
    function updateMermaid(event) {
      if (event.source === window && event.data && event.data.direction === ModeToggle.ID) {
        const mode = event.data.message;

        if (typeof mermaid === 'undefined') {
          return;
        }

        let expectedTheme = mode === ModeToggle.DARK_MODE ? 'dark' : 'default';
        let config = { theme: expectedTheme };

        /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $('.mermaid').each(function () {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr('data-processed');
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, '.mermaid');
      }
    }

    let initTheme = 'default';
    const html = document.documentElement;

    if (
      (html.hasAttribute('data-mode') && html.getAttribute('data-mode') === 'dark') ||
      (!html.hasAttribute('data-mode') && window.matchMedia('(prefers-color-scheme: dark)').matches)
    ) {
      initTheme = 'dark';
    }

    let mermaidConf = {
      theme: initTheme /* <default|dark|forest|neutral> */
    };

    /* Create mermaid tag */
    document.querySelectorAll('pre>code.language-mermaid').forEach((elem) => {
      const svgCode = elem.textContent;
      const backup = elem.parentElement;
      backup.classList.add('unloaded');
      /* create mermaid node */
      let mermaid = document.createElement('pre');
      mermaid.classList.add('mermaid');
      const text = document.createTextNode(svgCode);
      mermaid.appendChild(text);
      backup.after(mermaid);
    });

    mermaid.initialize(mermaidConf);

    window.addEventListener('message', updateMermaid);
  })();
</script>

    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/AI4science/assets/js/data/search.json',
    searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{snippet}</p>  </article>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

