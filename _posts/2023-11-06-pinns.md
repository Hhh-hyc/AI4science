---
layout: post
title: PINNs_Inference
date: 2023-11-4 12:00:00 +0800
categories: [Computational sciences]
tags: [pinn]
math: true
mermaid: true
---
Trained to solve `supervised learning tasks`, Physic-informed neural networks (PINNs) are defined for two classes of problems:
data-driven solution and data-driven discovery of partial differential equations (PDEs).

### Data-driven solution

Given a general form of PDEs $f(t,x)$, PINN could get to the solution $u(t,x)$ of this 1-D non-linear equation with only small amount of training data, namely initial and boundary conditions of $u(t,x)$ as well as sampled data of $f(t,x)$.

E.g., **Discrete time inference equation: Allen-Cahn equation**

$$ f(t,x)=u_{t}+uu_{xx}-(0.01/\pi)u_{xx} $$

By minimizing the mean square error loss $MSE_{u}+MSE_{f}$, 

$$ MSE_{u}=\frac{1}{N_{u}}\sum_{i=0}^{N_{u}}\lvert u(t_{u}^{i},x_{u}^{i})-u^{i} \rvert^2 $$ 

$$ MSE_{f}=\frac{1}{N_{f}}\sum_{i=0}^{N_{f}}\lvert f(t_{f}^{i},x_{f}^{i}) \rvert^2 $$

To approximate $u(t,x)$ by $f(t,x)$, neural networks are defined as follows:
1. Weights between layers are defined like `xavier_init`
```python
def xavier_init(self, size):
        in_dim = size[0]
        out_dim = size[1]        
        xavier_stddev = np.sqrt(2/(in_dim + out_dim))
        return tf.Variable(tf.truncated_normal([in_dim, out_dim], stddev=xavier_stddev), dtype=tf.float32)
```
2. Given the number of `layers`, weights and biases are produced by `initialize_NN`
```python
def initialize_NN(self, layers):        
        weights = []
        biases = []
        num_layers = len(layers) 
        for l in range(0,num_layers-1):
            W = self.xavier_init(size=[layers[l], layers[l+1]])
            b = tf.Variable(tf.zeros([1,layers[l+1]], dtype=tf.float32), dtype=tf.float32)
            weights.append(W)
            biases.append(b)        
        return weights, biases
```
3. Given weights and biases, a complete neural network without the final activation is designed by `neural_net`
```python
def neural_net(self, X, weights, biases):
        num_layers = len(weights) + 1
        H = 2.0*(X - self.lb)/(self.ub - self.lb) - 1.0
        for l in range(0,num_layers-2):
            W = weights[l]
            b = biases[l]
            H = tf.tanh(tf.add(tf.matmul(H, W), b))
        W = weights[-1]
        b = biases[-1]
        Y = tf.add(tf.matmul(H, W), b) # appending tanh?
        return Y
```
where, `H` seems like restricting the value of the first layer within [-1,1].
4. As weights, `dummy_x0(x1)_tf` is identity matirx of `x0(x1)` rows and `q` columns, leading to no changes at given case.
```python
def fwd_gradients_0(self, U, x):        
        g = tf.gradients(U, x, grad_ys=self.dummy_x0_tf)[0]
        return tf.gradients(g, self.dummy_x0_tf)[0] 
def fwd_gradients_1(self, U, x):        
    g = tf.gradients(U, x, grad_ys=self.dummy_x1_tf)[0]
    return tf.gradients(g, self.dummy_x1_tf)[0] 
```
5. Through `net_U0` and `net_U1`, $f(t,x)$ is generated by $U$ and $U_{xx}$, with the same dimension of $N$ x $q$, while $U1$ is generated  with a dimension of (N, q+1).
```python
def net_U0(self, x): # x0
        U1 = self.neural_net(x, self.weights, self.biases)
        U = U1[:,:-1]
        U_x = self.fwd_gradients_0(U, x)
        U_xx = self.fwd_gradients_0(U_x, x)
        F = 5.0*U - 5.0*U**3 + 0.0001*U_xx
        U0 = U1 - self.dt*tf.matmul(F, self.IRK_weights.T) # (N, q+1)-(N, q)=(N,q+1)
        return U0 
def net_U1(self, x): # x1
        U1 = self.neural_net(x, self.weights, self.biases)
        U1_x = self.fwd_gradients_1(U1, x)
        return U1, U1_x   #ï¼ˆ2, q+1)  
```
6. `loss` is defined by $u0$, products of functions of $net_{U0}$ and $net_{U1}$ in step 5.
```python
self.U0_pred = self.net_U0(self.x0_tf) # N x (q+1)
self.U1_pred, self.U1_x_pred= self.net_U1(self.x1_tf) # N1 x (q+1)
self.loss = tf.reduce_sum(tf.square(self.u0_tf - self.U0_pred)) + \   
               tf.reduce_sum(tf.square(self.U1_pred[0,:] - self.U1_pred[1,:])) + \
               tf.reduce_sum(tf.square(self.U1_x_pred[0,:] - self.U1_x_pred[1,:])) 
            # (N,1)-(N,q+1); (1,q+1)-(1,q+1); (1,q+1)-(1,q+1)
```
The first row of `self.loss` represents $MSE_{f}$;The second and third rows of `self.loss` represent $MSE_{u}$, with the initial and boundary data, $x1$.
7. input data:
+ $x0$ is resampled x, dimension (N x 1).
+ $u0$ randomly transposed row of u(t,x), results of specific `t`, with some noises (0 in Burger's equation), dimension(N x 1)
+ $x1$ is vertically stacked data [-1,1].
+ $dt$ is the random length of `t`, $t1-t0$, where $t0$ correponds to the position of $u0$.
+ `layers` is a list, representing the strusture of $f(t,x)$.
+ $q+1$ is the last element in `layers`, the target size at bounary condition, 100+1 samples.
8. Via `net_U1` function, a (N, q+1) matrix is predicted by inputing a certain value of `x*` (N,1) in the $U1_{pred}$, which is the target of PINNs, with error calculated by 
```python
error = np.linalg.norm(U1_pred[:,-1] - Exact[idx_t1,:], 2)/np.linalg.norm(Exact[idx_t1,:], 2)
```


**Questiona are,**
- why the neurons of the last layer is firstly set as (q+1), and then clip the dimension of $U$ to be (N, q), instead of initially settled down as (N, q) in step 5?
- the predicted matrix [:,:-1] (N,q) represents the distribution of solution $u(t,x)?
- In training, $net_{U1}$ is put $x1$ with a dimension of (2,1); while in testing, $net_{U1}$ is put `x*` with a dimension of (N,1). Why the dimension of input in `U1_pred` is different?

**Changes in versions of tensorflow**
- tf.compat.v1 should be added in front of some old v1 functions in v2 version of tensorflow.
- `L-BFGS-B` method in tf.opt.ScipyOptimizerInterface could be replaced by tensorflow_probability.optimizer.lbfgs_minimize()

**Explanations in programming**
- `tf.placeholder()` generates a map, different from tf. Varaibles() and tf.Tensor(). This type is hashable, while the other two are not.
  + placeholder() with a new name `.._tf` in tf_dict.keys() is irreplaceable.
- `tf.compat.v1.dsable_eager_execution()` couldn't be used, as in resources_variable_ops.py script, self.numpy() wouldn't be implemented.
  + To avoid loss in Adam shoule be a function in eager execution, if the disable function is used, then tensor.ref() is useless. As a result, tf.compat.v1.placeholder() couldn't be replaced by tenspr.ref()
  + As a result, tf.gradients is taken place by tf.GradientTape(), which requires targets to be a list or nested tensors. In the case of deep learning, the forward function should be appplied within GradientTape().
- Why both Adam and L-BFGS optimizer were used.
  + With only Adam, the error calculated by $np.linalg.norm$ between $U1_pred[:,-1]$ (512,1) and $x$ (1, 512) is 1.37,
  + With both Adam and L-BFGS, the error is 
- The effect of appending `tanh` in neural_net function.
- Effects of removing dummy_x0(x1)
  + They are removed in tf.GradientTape()
 
**Difference between discrete time inference and continuous one**

**Personal views**
- In th code of PINNs, it focues on the variation of `x` with a specific random value of `t`
- The innovation lies in the treatment of loss function
- What's the difference between `PINNs` and `adding physics constraints into loss function`[^foot1] ?

> Code is updated and simplified here
{: .prompt-info }

[^foot1]: Chen H, Huang J J, Dash S S, et al. A hybrid deep learning framework with physical process description for simulation of evapotranspiration[J]. Journal of Hydrology, 2022, 606: 127422.